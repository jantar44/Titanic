{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coding: utf-8\n",
    "\n",
    "<h1>Titanic</h1>\n",
    "RMS Titanic was a British passenger liner that sank in the North Atlantic Ocean in the early hours of 15 April 1912, after colliding with an iceberg during its maiden voyage from Southampton to New York City. There were an estimated 2,224 passengers and crew aboard, and more than 1,500 died, making it one of the deadliest commercial peacetime maritime disasters in modern history. RMS Titanic was the largest ship afloat at the time it entered service and was the second of three Olympic-class ocean liners operated by the White Star Line. It was built by the Harland and Wolff shipyard in Belfast.  <i>~Wikipedia</i>\n",
    "The iceberg unraveled the ship's hull at a length of 90 meters - the length of the hull plating was 90 m, but on the basis of the examination of the size of damage it was clearly stated that it was a series of cracks, the total area of which was just over 1 square meter (1.18), that is, it was equal to the body surface of an adult human.\n",
    "<b> This is my first more extensive program.</b> Writing it, I start my adventure with \"more serious programming\". This is a secound aproach, this time with OOP.\n",
    "\n",
    "<h4>Chapters:</h4>\n",
    "<i>\n",
    "    \n",
    "1. Library and data import\n",
    "    \n",
    "2. Analysis, data cleaning and visualization\n",
    "    \n",
    "3. Preparation of data for the model\n",
    "    \n",
    "4. Creating a model\n",
    "    \n",
    "5. Analysis of correctness of the solution and visualization\n",
    "    \n",
    "6. Method analysis\n",
    "\n",
    "7. Reporting the solution on kaggle\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Library and data import</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błędna ścieżka\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b8b4429658b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Błędna ścieżka\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #Plotting library\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "try:\n",
    "    train = pd.DataFrame(pd.read_csv('data/train.csv'))\n",
    "    test = pd.DataFrame(pd.read_csv('data/test.csv'))\n",
    "    test_w = pd.DataFrame(pd.read_csv('data/test.csv'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Błędna ścieżka\")\n",
    "\n",
    "test.set_index('PassengerId', inplace=True)\n",
    "train.set_index('PassengerId', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Analysis, data cleaning and visualization</b>\n",
    "\n",
    "<i>\n",
    "2.1. Sex<br>\n",
    "2.2. Class<br>\n",
    "2.3. Embarkment<br>\n",
    "2.4. Family size<br>\n",
    "2.5. Fare<br>\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_null(column):\n",
    "    return column.isnull().sum()\n",
    "\n",
    "def filling_NaN(column):\n",
    "    null_n = info_null(column)\n",
    "    \n",
    "    if null_n > 0 and (null_n <= 50):\n",
    "        message = 'There are %d fields missing, they are filled with most common value: \"%s\"' % (null_n, column.mode()[0])\n",
    "        column.fillna(column.mode()[0], inplace = True)\n",
    "    if null_n > 50:\n",
    "        message = 'There is over 50 empty fields. A more accurate approximation is recommended.'    \n",
    "    else:\n",
    "        message = 'There are no empty fields.'\n",
    "    \n",
    "    return message\n",
    "\n",
    "def family_merge(dataset):\n",
    "    if 'FamilySize' not in dataset.columns:\n",
    "        dataset['FamilySize'] = dataset['Parch'] + dataset['SibSp']\n",
    "\n",
    "def info_discrete(column):\n",
    "    print(filling_NaN(column))\n",
    "    \n",
    "    categories = column.unique()\n",
    "    survived_perc = list()\n",
    "    labels = list()\n",
    "    for label in categories:\n",
    "        labels.append(label)\n",
    "        survived_perc.append([label, train.Survived[column == label].value_counts(normalize=True).sort_index()][1][1])\n",
    "\n",
    "    plot1 = plt.plot(labels, survived_perc, 'bo')\n",
    "    plt.title('Survival rate('+column.name+')')\n",
    "    return plot1\n",
    "\n",
    "def info_continous(column, step):\n",
    "    print(filling_NaN(column))\n",
    "    \n",
    "    scope = column.max() - column.min() - step\n",
    "    survived_perc = list()\n",
    "    labels = list()\n",
    "    for i in range(0, int(scope), step):\n",
    "        survived_perc.append(train.Survived[column.between(i, i+5)].mean())\n",
    "        labels.append(i)\n",
    "        \n",
    "    plot2 = plt.plot(labels, survived_perc, 'bo', ls = '-')\n",
    "    plt.title('Survival rate('+column.name+')')\n",
    "    return plot2\n",
    "\n",
    "def number_cases(column, step):\n",
    "    scope = column.max() - column.min() - step\n",
    "    survived_num = list()\n",
    "    labels = list()\n",
    "    for i in range(0, int(scope), step):\n",
    "        survived_num.append(train.Survived[column.between(i, i+5)].count())\n",
    "        labels.append(i)\n",
    "        \n",
    "    plot3 = plt.bar(labels, survived_num, align = 'center')\n",
    "    plt.title('Number of cases('+column.name+')')\n",
    "    return plot3\n",
    "\n",
    "info_discrete(train['Sex'])\n",
    "\n",
    "info_discrete(train['Pclass'])\n",
    "\n",
    "info_discrete(train['Embarked'])\n",
    "\n",
    "info_continous(train['Age'],3)\n",
    "\n",
    "number_cases(train['Age'],1)\n",
    "\n",
    "info_continous(train['Fare'],8)\n",
    "\n",
    "number_cases(train['Fare'],8)\n",
    "\n",
    "#Due to the small amount of cases and shape of the previous graph showing the percentage of survivors, values above 50 inclusive will be marked as 50.\n",
    "\n",
    "family_merge(train)\n",
    "family_merge(test)\n",
    "\n",
    "info_continous(train['FamilySize'],1)\n",
    "\n",
    "number_cases(train['FamilySize'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Data preparation </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(int(test['Fare'].median()), inplace = True)\n",
    "\n",
    "\n",
    "train.drop(['Ticket', 'Cabin', 'Name'], axis = 1,inplace = True)\n",
    "test.drop(['Ticket', 'Cabin', 'Name'], axis = 1, inplace = True)\n",
    "\n",
    "test['Sex'] = test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "train['Sex'] = train['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "data = train.append(test, sort = True)\n",
    "\n",
    "for i in range(1,1310):\n",
    "    if data.loc[i, 'Sex'] == 1 and (data.loc[i, 'Pclass'] == 1):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 41\n",
    "    if data.loc[i, 'Sex'] == 0 and (data.loc[i, 'Pclass'] == 1):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 37\n",
    "    if data.loc[i, 'Sex'] == 1 and (data.loc[i, 'Pclass'] == 2):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 31\n",
    "    if data.loc[i, 'Sex'] == 0 and (data.loc[i, 'Pclass'] == 2):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 27\n",
    "    if data.loc[i, 'Sex'] == 1 and (data.loc[i, 'Pclass'] == 3):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 26\n",
    "    if data.loc[i, 'Sex'] == 0 and (data.loc[i, 'Pclass'] == 3):\n",
    "        if np.isnan(data.loc[i, 'Age']):\n",
    "            data.loc[i, 'Age'] = 22\n",
    "\n",
    "data.drop(['SibSp', 'Parch'],axis=1,inplace=True)\n",
    "\n",
    "data['Embarked'] = data['Embarked'].map({'S':1, 'C':2, 'Q':3}).astype(int)\n",
    "\n",
    "data.loc[ data['Fare'] > 50, 'Fare'] = 50\n",
    "data['Fare'] = data['Fare'].astype(int)\n",
    "\n",
    "training = data.iloc[:891,:]\n",
    "testing = data.iloc[891:,:]\n",
    "trainY = training['Survived']\n",
    "trainX = training.drop(['Survived'], axis = 1)\n",
    "testX = testing.drop(['Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4. Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = list(range(1,50))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, trainX, trainY, cv=10, scoring='f1')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "def model_choice(trainX, trainY, testX):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC, LinearSVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    reglog = LogisticRegression()\n",
    "    reglog.fit(trainX, trainY)\n",
    "    Y_predLR = reglog.predict(testX)\n",
    "    acc_log = round(reglog.score(trainX, trainY) * 100, 2)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(trainX, trainY)\n",
    "    Y_predKNN = knn.predict(testX)\n",
    "    acc_knn = round(knn.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    gaussian = GaussianNB()\n",
    "    gaussian.fit(trainX, trainY)\n",
    "    Y_predG = gaussian.predict(testX)\n",
    "    acc_gaussian = round(gaussian.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    perceptron = Perceptron()\n",
    "    perceptron.fit(trainX, trainY)\n",
    "    Y_predP = perceptron.predict(testX)\n",
    "    acc_perceptron = round(perceptron.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(trainX, trainY)\n",
    "    Y_pred = svc.predict(testX)\n",
    "    acc_svc = round(svc.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    linear_svc = LinearSVC()\n",
    "    linear_svc.fit(trainX, trainY)\n",
    "    Y_predLSVC = linear_svc.predict(testX)\n",
    "    acc_linear_svc = round(linear_svc.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    sgd = SGDClassifier()\n",
    "    sgd.fit(trainX, trainY)\n",
    "    Y_predSGD = sgd.predict(testX)\n",
    "    acc_sgd = round(sgd.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(trainX, trainY)\n",
    "    Y_predD = decision_tree.predict(testX)\n",
    "    acc_decision_tree = round(decision_tree.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=400, max_features = 'sqrt', oob_score = True, n_jobs = -1)\n",
    "    random_forest.fit(trainX, trainY)\n",
    "    Y_predRF = random_forest.predict(testX)\n",
    "    random_forest.score(trainX, trainY)\n",
    "    acc_random_forest = round(random_forest.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "    print('LogisticRegression =', acc_log)\n",
    "    print('KNeighborsClassifier =', acc_knn)\n",
    "    print('GaussianNB =', acc_gaussian)\n",
    "    print('Perceptron =', acc_perceptron)\n",
    "    print('LinearSVC =', acc_linear_svc)\n",
    "    print('SVC =', acc_svc)\n",
    "    print('SGDClassifier =', acc_sgd)\n",
    "    print('DecisionTreeClassifier =', acc_decision_tree)\n",
    "    print('RandomForestClassifier =', acc_random_forest)\n",
    "\n",
    "model_choice(trainX, trainY, testX)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=400, max_features = 'sqrt', oob_score = True, n_jobs = -1)\n",
    "random_forest.fit(trainX, trainY)\n",
    "Y_predRF = random_forest.predict(testX).astype('int64', copy = False)\n",
    "random_forest.score(trainX, trainY)\n",
    "acc_random_forest = round(random_forest.score(trainX, trainY) * 100, 2)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_w[\"PassengerId\"],\n",
    "        \"Survived\": Y_predRF\n",
    "    })\n",
    "\n",
    "submission.to_csv('/home/jan/Dokumenty/MINT/Kaggle/Tytanic/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
